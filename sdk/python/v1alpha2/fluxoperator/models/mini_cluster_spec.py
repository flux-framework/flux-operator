# coding: utf-8

"""
    fluxoperator

    Python SDK for Flux-Operator

    The version of the OpenAPI document: v1alpha2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from fluxoperator.models.flux_spec import FluxSpec
from fluxoperator.models.logging_spec import LoggingSpec
from fluxoperator.models.mini_cluster_archive import MiniClusterArchive
from fluxoperator.models.mini_cluster_container import MiniClusterContainer
from fluxoperator.models.network import Network
from fluxoperator.models.pod_spec import PodSpec
from typing import Optional, Set
from typing_extensions import Self

class MiniClusterSpec(BaseModel):
    """
    MiniCluster is an HPC cluster in Kubernetes you can control Either to submit a single job (and go away) or for a persistent single- or multi- user cluster
    """ # noqa: E501
    archive: Optional[MiniClusterArchive] = None
    cleanup: Optional[StrictBool] = Field(default=False, description="Cleanup the pods and storage when the index broker pod is complete")
    containers: List[MiniClusterContainer] = Field(description="Containers is one or more containers to be created in a pod. There should only be one container to run flux with runFlux")
    deadline_seconds: Optional[StrictInt] = Field(default=31500000, description="Should the job be limited to a particular number of seconds? Approximately one year. This cannot be zero or job won't start", alias="deadlineSeconds")
    flux: Optional[FluxSpec] = None
    interactive: Optional[StrictBool] = Field(default=False, description="Run a single-user, interactive minicluster")
    job_labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="Labels for the job", alias="jobLabels")
    logging: Optional[LoggingSpec] = None
    max_size: Optional[StrictInt] = Field(default=None, description="MaxSize (maximum number of pods to allow scaling to)", alias="maxSize")
    min_size: Optional[StrictInt] = Field(default=None, description="MinSize (minimum number of pods that must be up for Flux) Note that this option does not edit the number of tasks, so a job could run with fewer (and then not start)", alias="minSize")
    network: Optional[Network] = None
    pod: Optional[PodSpec] = None
    services: Optional[List[MiniClusterContainer]] = Field(default=None, description="Services are one or more service containers to bring up alongside the MiniCluster.")
    share_process_namespace: Optional[StrictBool] = Field(default=False, description="Share process namespace?", alias="shareProcessNamespace")
    size: Optional[StrictInt] = Field(default=1, description="Size (number of job pods to run, size of minicluster in pods) This is also the minimum number required to start Flux")
    tasks: Optional[StrictInt] = Field(default=1, description="Total number of CPUs being run across entire cluster")
    __properties: ClassVar[List[str]] = ["archive", "cleanup", "containers", "deadlineSeconds", "flux", "interactive", "jobLabels", "logging", "maxSize", "minSize", "network", "pod", "services", "shareProcessNamespace", "size", "tasks"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of MiniClusterSpec from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of archive
        if self.archive:
            _dict['archive'] = self.archive.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in containers (list)
        _items = []
        if self.containers:
            for _item in self.containers:
                if _item:
                    _items.append(_item.to_dict())
            _dict['containers'] = _items
        # override the default output from pydantic by calling `to_dict()` of flux
        if self.flux:
            _dict['flux'] = self.flux.to_dict()
        # override the default output from pydantic by calling `to_dict()` of logging
        if self.logging:
            _dict['logging'] = self.logging.to_dict()
        # override the default output from pydantic by calling `to_dict()` of network
        if self.network:
            _dict['network'] = self.network.to_dict()
        # override the default output from pydantic by calling `to_dict()` of pod
        if self.pod:
            _dict['pod'] = self.pod.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in services (list)
        _items = []
        if self.services:
            for _item in self.services:
                if _item:
                    _items.append(_item.to_dict())
            _dict['services'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of MiniClusterSpec from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "archive": MiniClusterArchive.from_dict(obj["archive"]) if obj.get("archive") is not None else None,
            "cleanup": obj.get("cleanup") if obj.get("cleanup") is not None else False,
            "containers": [MiniClusterContainer.from_dict(_item) for _item in obj["containers"]] if obj.get("containers") is not None else None,
            "deadlineSeconds": obj.get("deadlineSeconds") if obj.get("deadlineSeconds") is not None else 31500000,
            "flux": FluxSpec.from_dict(obj["flux"]) if obj.get("flux") is not None else None,
            "interactive": obj.get("interactive") if obj.get("interactive") is not None else False,
            "jobLabels": obj.get("jobLabels"),
            "logging": LoggingSpec.from_dict(obj["logging"]) if obj.get("logging") is not None else None,
            "maxSize": obj.get("maxSize"),
            "minSize": obj.get("minSize"),
            "network": Network.from_dict(obj["network"]) if obj.get("network") is not None else None,
            "pod": PodSpec.from_dict(obj["pod"]) if obj.get("pod") is not None else None,
            "services": [MiniClusterContainer.from_dict(_item) for _item in obj["services"]] if obj.get("services") is not None else None,
            "shareProcessNamespace": obj.get("shareProcessNamespace") if obj.get("shareProcessNamespace") is not None else False,
            "size": obj.get("size") if obj.get("size") is not None else 1,
            "tasks": obj.get("tasks") if obj.get("tasks") is not None else 1
        })
        return _obj



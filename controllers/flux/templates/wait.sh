#!/bin/sh

# This waiting script is run continuously and only updates
# hosts and runs the job (breaking from the while) when 
# update_hosts.sh has been populated. This means the pod usually
# needs to be updated with the config map that has ips!

# Always run flux commands (and the broker) as flux user
asFlux="sudo -u flux -E"

# If any preCommand logic is defined
{{ .PreCommand}}

# We currently require sudo and an ubuntu base
which sudo || (echo "sudo is required to be installed" && exit 1);
which flux || (echo "flux is required to be installed" && exit 1);

# Broker Options: important!
# The local-uri setting places the unix domain socket in rundir 
#   if FLUX_URI is not set, tools know where to connect.
#   -Slog-stderr-level= can be set to 7 for larger debug level
#   or exposed as a variable
brokerOptions="-Scron.directory=/etc/flux/system/cron.d \
  -Stbon.fanout=256 \
  -Srundir=/run/flux \
  -Sstatedir=${STATE_DIRECTORY:-/var/lib/flux} \
  -Slocal-uri=local:///run/flux/local \
  -Slog-stderr-level=6 \
  -Slog-stderr-mode=local"

# quorum settings influence how the instance treats missing ranks
#   by default all ranks must be online before work is run, but
#   we want it to be OK to run when a few are down
# These are currently removed because we want the main rank to
# wait for all the others, and then they clean up nicely
#  -Sbroker.quorum=0 \
#  -Sbroker.quorum-timeout=none \

# This should be added to keep running as a service
#  -Sbroker.rc2_none \

# Run diagnostics instead of a command
run_diagnostics() {
    printf "\nüê∏ ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions} flux overlay status\n"
    ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions} flux overlay status
    printf "\nüê∏ ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions} flux lsattr -v\n"
    ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions} flux lsattr -v
    printf "\nüê∏ ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions} flux dmesg\n"
    ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions} flux dmesg
    printf "\nüí§ sleep infinity\n"
    sleep infinity
}

# The statedir similarly should exist and have plenty of available space.
# If there are differences in containers / volumes this could eventually be
# exposed as STATEDIR variable
export STATE_DIR=/var/lib/flux
mkdir -p ${STATE_DIR}

# Cron directory
mkdir -p /etc/flux/system/cron.d

# uuid for flux token (auth)
FLUX_TOKEN="{{ .FluxToken}}"

# Main host <name>-0
mainHost="{{ .MainHost}}"

# The working directory should be set by the CRD or the container
workdir=${PWD}

printf "\nüëã Hello, I'm $(hostname)\n"
printf "The main host is ${mainHost}\n"
printf "The working directory is ${workdir}\n"
ls ${workdir}

# These actions need to happen on all hosts
# Configure resources
mkdir -p /etc/flux/system

# --cores=IDS Assign cores with IDS to each rank in R, so we  assign 1-N to 0
flux R encode --hosts={{ .Hosts}} > /etc/flux/system/R
printf "\nüì¶ Resources\n"
cat /etc/flux/system/R

# Do we want to run diagnostics instead of regular entrypoint?
diagnostics="{{ .Diagnostics}}"
printf "\nüê∏ Diagnostics: ${diagnostics}\n"


# Flux option flags
option_flags="{{ .FluxOptionFlags}}"
if [ "${option_flags}" != "" ]; then
    # Make sure we don't get rid of any already defined flags
    existing_flags="${FLUX_OPTION_FLAGS:-}"

    # provide them first so they are replaced by new ones here
    if [ "${existing_flags}" != "" ]; then
        export FLUX_OPTION_FLAGS="${existing_flags} ${option_flags}"
    else 
        export FLUX_OPTION_FLAGS="${option_flags}"
    fi
    echo "üö©Ô∏è Flux Option Flags defined"
fi

mkdir -p /etc/flux/imp/conf.d/
cat <<EOT >> /etc/flux/imp/conf.d/imp.toml
[exec]
allowed-users = [ "flux", "root" ]
allowed-shells = [ "/usr/libexec/flux/flux-shell" ]	
EOT

printf "\nü¶ä Independent Minister of Privilege\n"
cat /etc/flux/imp/conf.d/imp.toml

printf "\nüê∏ Broker Configuration\n"
cat /etc/flux/config/broker.toml 

# Add a flux user (required)
sudo adduser --disabled-password --uid 1000 --gecos "" flux || printf "flux user is already added.\n"

# Generate curve certificate (only need one shared)
if [ $(hostname) == "${mainHost}" ]; then
    printf "\n‚ú® Curve certificate being generated by $(hostname)\n"
    flux keygen /mnt/curve/curve.cert
    cat /mnt/curve/curve.cert

    # Each node needs same munge key
    cp /etc/munge/munge.key /mnt/curve/munge.key
else

    # Wait for main node to copy over its key
    while [ ! -f /mnt/curve/munge.key ];
    do
        printf "Shared munge key not available yet, waiting...\n"
        sleep 5s
    done
    while [ ! -f /mnt/curve/curve.cert ];
    do
        printf "Curve certificate not available yet, waiting...\n"
        sleep 5s
    done
    cp /mnt/curve/munge.key /etc/munge/munge.key
fi

# The rundir needs to be created first, and owned by user flux
# Along with the state directory and curve certificate
mkdir -p /run/flux

# We must get the correct flux user id - this user needs to own
# the run directory and these others
fluxuid=$(id -u flux)
chown -R ${fluxuid} /run/flux ${STATE_DIR} /mnt/curve/curve.cert ${workdir}

# Are we running diagnostics or the start command?
if [ "${diagnostics}" == "true" ]; then
    run_diagnostics
else

    # Start flux with the original entrypoint
    if [ $(hostname) == "${mainHost}" ]; then

        # No command - use default to start server
        echo "Extra arguments are: $@"
        if [ "$@" == "" ]; then

            # Start restful API server
            startServer="uvicorn app.main:app --host=0.0.0.0 --port=5000"
            git clone -b {{.FluxRestfulBranch }} --depth 1 https://github.com/flux-framework/flux-restful-api /flux-restful-api 
            cd /flux-restful-api

            # Install python requirements, with preference for python3
            python3 -m pip install -r requirements.txt || python -m pip install -r requirements.txt

            # Generate a random flux token
            FLUX_USER=flux 
            FLUX_REQUIRE_AUTH=true
            FLUX_NUMBER_NODES={{ .ClusterSize}}
            export FLUX_TOKEN FLUX_USER FLUX_REQUIRE_AUTH FLUX_NUMBER_NODES

            printf "\n üîë Your Credentials! These will allow you to control your MiniCluster with flux-framework/flux-restful-api\n"
            printf "export FLUX_TOKEN=${FLUX_TOKEN}\n"
            printf "export FLUX_USER=${FLUX_USER}\n"

            # -o is an "option" for the broker
            # -S corresponds to a shortened --setattr=ATTR=VAL
            printf "\nüåÄ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions} ${startServer}\n"
            ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions} ${startServer}

        # Case 2: Fall back to provided command
        else
            printf "\nüåÄ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions} $@\n"
            ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions} $@
        fi
    else 
        printf "\nüò™ Sleeping to give RESTful server time to start...\n"
        sleep 20

        # TODO tomorrow - try exposing port to see if this works. if yes, remove extra and repull container.
        # then add section for extra commands to run per container.
        # maybe wait.sh should be generated on level of container?
        # Just run start on worker nodes, with some delay to let rank 0 start first
        printf "\nüåÄ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions}\n"

        # We have the sleep here to give the main rank some time to start first (and not miss the workers)
        ${asFlux} flux start -o --config /etc/flux/config ${brokerOptions}
    fi
fi

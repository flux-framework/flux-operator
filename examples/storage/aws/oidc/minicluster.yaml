apiVersion: flux-framework.org/v1alpha1
kind: MiniCluster
metadata:
  name: flux-sample
  namespace: flux-operator
spec:

  # Number of pods to create for MiniCluster
  size: 2

  # Cleanup the storage volume (PVC and PV) after run
  # Leave this to false so you can see the log in the pod output
  cleanup: false

  # show all operator output and test run output
  logging:
    quiet: false

  # Make this kind of persistent volume and claim available to pods
  # This is a type of storage that will use Google Storage
  volumes:
    data:
      storageClass: hostpath
      # this is where the hostpath will mount storage
      # This MUST be in /tmp root to delete correctly
      path: /tmp/data

  # This is a list because a pod can support multiple containers
  containers:

      # This image has snakemake installed, and although it has data, we will 
      # provide it as a volume to the container to demonstrate that (and share it)
    - image: ghcr.io/rse-ops/atacseq:app-latest

      # We are saying to mount the "data" volume defined above to "/workflow"
      # in the container
      volumes:
        data:
          # This is where we will bind storage
          # E.g., /mnt/s3data is bound to /var/s3 or /mnt/s3data:/var/s3
          path: /var/s3
          # readOnly defaults to false
                
      # This should be the directory with the Snakefile
      workingDir: /var/s3/snakemake-workflow
      command: snakemake --cores 1 --flux

      # Commands just for workers / broker
      commands:

        # This is currently required for the storage driver to work
        runFluxAsRoot: true